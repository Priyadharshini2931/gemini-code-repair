name: SWE-bench Pro Evaluation
on:
  workflow_dispatch:
    inputs:
      task_id:
        description: 'Task ID to run'
        required: true
        default: 'internetarchive__openlibrary-c4eebe6677acc4629cb541a98d5e91311444f5d4'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    container:
      image: manojva/openlibrary-python312:latest
      options: --user root

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Environment
        run: bash setup_repository.sh
        env:
          TASK_ID: ${{ github.event.inputs.task_id }}

      - name: Pre-verification (Expect Failure)
        id: pre_test
        continue-on-error: true
        run: |
          cd /testbed
          python -m pytest openlibrary/tests/core/test_imports.py::TestImportItem::test_find_staged_or_pending -xvs > /github/workspace/pre_verification.log 2>&1

      - name: Run AI Agent (Gemini)
        run: python run_agent.py
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          TASK_ID: ${{ github.event.inputs.task_id }}

      - name: Post-verification (Expect Success)
        id: post_test
        run: |
          cd /testbed
          python -m pytest openlibrary/tests/core/test_imports.py::TestImportItem::test_find_staged_or_pending -xvs > /github/workspace/post_verification.log 2>&1

      - name: Extract Metrics
        run: python extract_metrics.py

      - name: Generate Patch
        run: |
          cd /testbed
          git diff > /github/workspace/changes.patch

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: |
            agent.log
            result.json
            pre_verification.log
            post_verification.log
            changes.patch
            prompts.md
